{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import Request\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import geopandas\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page 1\n",
      "Downloading page 2\n",
      "Downloading page 3\n",
      "Downloading page 4\n",
      "Downloading page 5\n",
      "Downloading page 6\n",
      "Downloading page 7\n",
      "Downloading page 8\n",
      "Downloading page 9\n",
      "Downloading page 10\n",
      "Downloading page 11\n",
      "Downloading page 12\n",
      "Downloading page 13\n",
      "Downloading page 14\n",
      "Downloading page 15\n",
      "Downloading page 16\n",
      "Downloading page 17\n",
      "Downloading page 18\n",
      "Downloading page 19\n",
      "Downloading page 20\n",
      "Downloading page 21\n",
      "Downloading page 22\n",
      "Downloading page 23\n",
      "Downloading page 24\n",
      "Downloading page 25\n",
      "Downloading page 26\n",
      "Downloading page 27\n",
      "Downloading page 28\n",
      "Downloading page 29\n",
      "Downloading page 30\n",
      "Downloading page 31\n",
      "Downloading page 32\n",
      "Downloading page 33\n",
      "Downloading page 34\n",
      "Downloading page 35\n",
      "Downloading page 36\n",
      "Downloading page 37\n",
      "Downloading page 38\n",
      "Downloading page 39\n",
      "Downloading page 40\n",
      "Downloading page 41\n",
      "Downloading page 42\n",
      "Downloading page 43\n",
      "Downloading page 44\n",
      "Downloading page 45\n",
      "Downloading page 46\n",
      "Downloading page 47\n",
      "Downloading page 48\n",
      "Downloading page 49\n",
      "Downloading page 50\n",
      "Downloading page 51\n",
      "Downloading page 52\n",
      "Downloading page 53\n",
      "Downloading page 54\n",
      "Downloading page 55\n",
      "Downloading page 56\n",
      "Downloading page 57\n",
      "Downloading page 58\n",
      "Downloading page 59\n",
      "Downloading page 60\n",
      "Downloading page 61\n",
      "Downloading page 62\n",
      "Downloading page 63\n",
      "Downloading page 64\n",
      "Downloading page 65\n",
      "Downloading page 66\n",
      "Downloading page 67\n",
      "Downloading page 68\n",
      "Downloading page 69\n",
      "Downloading page 70\n",
      "Downloading page 71\n",
      "Downloading page 72\n",
      "Downloading page 73\n",
      "Downloading page 74\n",
      "Downloading page 75\n",
      "Downloading page 76\n",
      "Downloading page 77\n",
      "Downloading page 78\n",
      "Downloading page 79\n",
      "Downloading page 80\n",
      "Downloading page 81\n",
      "Downloading page 82\n",
      "Downloading page 83\n",
      "Downloading page 84\n",
      "Downloading page 85\n",
      "Downloading page 86\n",
      "Downloading page 87\n",
      "Downloading page 88\n",
      "Downloading page 89\n",
      "Downloading page 90\n",
      "Downloading page 91\n",
      "Downloading page 92\n",
      "Downloading page 93\n",
      "Downloading page 94\n",
      "Downloading page 95\n",
      "Downloading page 96\n",
      "Downloading page 97\n",
      "Downloading page 98\n",
      "Downloading page 99\n"
     ]
    }
   ],
   "source": [
    "otodom = 'https://www.otodom.pl/pl/oferty/sprzedaz/mieszkanie/krakow?page='\n",
    "pages = []\n",
    "\n",
    "for page in range(1, 100):\n",
    "    \n",
    "    print(f\"Downloading page {page}\")\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(f\"{url}{page}\") as response:\n",
    "            processed_page = BeautifulSoup(response.read().decode(\"utf-8\"), \"html.parser\")\n",
    "            pages.append(processed_page)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_previews = []\n",
    "\n",
    "for page in pages:\n",
    "    offer_previews += page.find_all('a', {\"data-cy\" : \"listing-item-link\"})\n",
    "\n",
    "offer_prefix = \"https://www.otodom.pl\"\n",
    "offers = []\n",
    "\n",
    "for offer in offer_previews:\n",
    "    offer_suffix = offer['href']\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(f\"{offer_prefix}{offer_suffix}\") as response:\n",
    "            processed_offer = BeautifulSoup(response.read().decode(\"utf-8\"), \"html.parser\")\n",
    "            pages.append(processed_offer)\n",
    "\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
